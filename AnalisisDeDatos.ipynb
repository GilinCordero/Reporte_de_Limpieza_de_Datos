{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40e3a732",
   "metadata": {},
   "source": [
    "# Análisis y Limpieza de Datos -- Procedimiento para Catalogar Cáncer Luminal A y B\n",
    "\n",
    "Este archivo contiene el proceso de limpieza, exploración y análisis de la base de datos del proyecto de de cáncer de mama en base a la información de los diagnosticos de diversos pacientes registrados por la Secretaria de Salud.\n",
    "\n",
    "mas info sobre lo q buscamos\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0927935f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero de columnas/variables: 109 \n",
      "\n",
      "Columnas identificadas: \n",
      " ['Id', 'Fecha_De_Registro', 'Fecha_De_Nacimiento', 'Fecha_De_Dx_Biopsia', 'Edad_Al_Dx_(Años)', 'Fecha_1°_Consulta_Om_Cecan', 'Peso_Al_Dx', 'Talla_Al_Dx', 'Imc', 'Edo_Menopausia_Dx', 'Preservación_De_La_Fertilidad', 'Prueba_Genetica', 'Resultado_Panel_Genético', 'Otra_Mutación', 'Significado', 'Cm_Bilateral', 'Cm_Asociado_Al_Embarazo', 'Ec', 'T', 'N', 'M', 'Tipo_Histológico', 'Otro', 'Grado', 'Er', 'Er_%', 'Pr', 'Pr_%', 'Her2_/_Neu', 'Her2_Ihq_+++', 'Fish/Sish', 'Ki67', 'Ki67_%', 'Ilv', 'Tils', 'Tils_%', 'Patología_Rev_Cecan', 'Tx_Neoadyuvante', 'Tx_Neoadyuvante_Cecan', 'Quimioterapia_Neoadyuvante', 'Esquema_Qt_Neoadyuvante', 'Antiher2_Neoadyuvante', 'Esquema_Antiher2_Neoadyuvante', 'Inmunoterapia_Neoadyuvante', 'Comentarios_Tx_Neoadyuvante', 'Respuesta_Patológica_Completa', 'Ypt', 'Ypn', 'Rbc', 'Fecha_De_Cx', 'Cx_Cecan', 'Tipo_Cx_Mama', 'Manejo_Axila', 'Requirio_2°_Cx_De_Mama', 'Cual', 'Rt_Adyuvante', 'Tipo_Rt_Ady', 'Analógos_Gnrh_Como_Protector_Ovarico', 'Tx_Adyuvante', 'Tx_Adyuvante_Cecan', 'Quimioterapia_Adyuvante', 'Esquema_Qt_Adyuvante', 'Capecitabina', 'Antiher2_Adyuvante', 'Esquema_Antiher2_Adyuvante', 'Inmunoterapia_Adyuvante', 'Olaparib_Adyuvante', 'Abemaciclib_Adyuvante', 'Adyuvancia_Endócrina_', 'Adyuvancia_Endócrina_Cecan', 'Tipo_Tx_Antihormonal_(2_Primeros_Años)', 'Switch_Hormonal_(Despues_De_2_Años)', 'Supresión_Ovarica', 'Fecha_Inicio_Adyuvancia_Endócrina', 'Fin_De_Adyuvancia_Endócrina', 'Fecha_Fin_Adyuvancia_Endócrina', 'Adyuvancia_Extendida', 'Ac._Zoledrónico/Denosumab_Adyuvante', 'Recurrencia_Local', 'Fecha_1°_Recurrencia_Local', 'Sle_(Meses)', 'No._De_Recurrencias_Locales', 'Recurrencia_Sistémica', 'Fecha_1°_Recurrencia_Sistémica', 'Slem_(Meses)', 'Biopsia_De_1°_Recurrencia_(Local_O_Sistémica)', 'Er_Recurrencia', 'Pr_Recurrencia', 'Her2_Ihq_Recurrencia', 'Her2_Ihq_+++.1', 'Icdk_4/6_Enfermedad__Metastásica', 'Tipo_Icdk_4/6', 'Inmunoterapia_Enfermedad_Metastásica', 'Tipo_Inmunoterapia', 'Iparp_Enfermedad_Metastásica', 'Estado_En_Ultimo_Seguimiento', 'Fecha_De_Ultimo_Seguimiento', 'Fecha_De_Muerte', 'Seguimiento_(Meses)', 'Sg_(Meses)', 'Muerte_Por_Ca_De_Mama', 'Ooforectomía', 'Mastecomía_Contralateral_2°_Tiempo', 'Embarazo_Post_Cm', '2°_Primario', 'Sitio', 'Protocolo_De_Investigación_', 'Nombre_De_Protocolo', 'Comentarios']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Leemos la Base de Datos\n",
    "df = pd.read_csv('./resources/2025_08_27 BD Proy Salud.csv', encoding='latin1')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#hay dos Er_%, uno con _ y oyto con espacio, lo mismo con Pr_%, elimina los que tienen espacios\n",
    "df = df.drop(columns=['ER %', 'PR %'])\n",
    "\n",
    "\n",
    "#Renombramos columnas para agregar _ entre espacios\n",
    "\n",
    "df.columns = df.columns.str.replace(' ', '_')\n",
    "df.columns = df.columns.str.title()\n",
    "\n",
    "#Sacamos columnas disponibles para facilidad de lectura posterior\n",
    "unique_columns = df.columns.tolist()\n",
    "\n",
    "print(\"Numero de columnas/variables:\", len(unique_columns), \"\\n\")\n",
    "print(\"Columnas identificadas: \\n\", unique_columns)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692a6b98",
   "metadata": {},
   "source": [
    "En esta acción inicial: \n",
    "- Modificamos los nombres de las columnas para manipularlas de manera más sencilla\n",
    "- Modificamos nombres similares para las variables de recurrencia de PR y ER para no ser confundidas con el porcentaje de PR y ER\n",
    "- Retornamos una lista de todas las columnas para identificar mejoras, errores, y verificar cuales no son más utiles de una manera más eficiente\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e28679",
   "metadata": {},
   "source": [
    "---\n",
    "##### Creamos una sub-tabla con las columnas que corresponden a el objetivo de nuestro análisis\n",
    "\n",
    "Seleccionamos datos de interés para el análisis de cáncer luminal, además de datos demográficos básicos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ac6f6fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros: 1366\n"
     ]
    }
   ],
   "source": [
    "#Seleccionamos datos de interés para el análisis de cáncer luminal, además de datos demográficos básicos\n",
    "\n",
    "luminal_columns = [\n",
    "    'Id', 'Fecha_De_Registro', 'Fecha_De_Nacimiento', 'Fecha_De_Dx_Biopsia', 'Edad_Al_Dx_(Años)',\n",
    "    'Fecha_1°_Consulta_Om_Cecan', 'Peso_Al_Dx', 'Talla_Al_Dx', 'Er_%', 'Pr_%', 'Her2_/_Neu',\n",
    "    'Her2_Ihq_+++','Fish/Sish', 'Ki67_%', 'Grado'\n",
    "]\n",
    "\n",
    "#Nuevo DataFrame con columnas de interés\n",
    "luminalDf = df[luminal_columns]\n",
    "\n",
    "#Mostramos todas las columnas y los primeros registros\n",
    "pd.set_option('display.max_columns', None)\n",
    "luminalDf.head()\n",
    "\n",
    "\n",
    "print(\"Cantidad de registros:\", luminalDf.shape[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb2c45",
   "metadata": {},
   "source": [
    "# Antes de comenzar...\n",
    "\n",
    "Previo a cualquier análisis, necesitamos limpiar repeticiones, datos redundantes entre otros errores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "40cac6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros: 1366\n"
     ]
    }
   ],
   "source": [
    "#Observamos la cantidad de registros que tenemos\n",
    "\n",
    "print(\"Cantidad de registros:\", luminalDf.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ad1a9d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cantidad de registros después de la limpieza: 1351\n"
     ]
    }
   ],
   "source": [
    "#Limpiamos IDs repetidos y nulos, nos quedamos con los primeros repetidos\n",
    "\n",
    "luminalDf = luminalDf.drop_duplicates(subset=['Id'], keep='first')\n",
    "luminalDf = luminalDf[luminalDf['Id'].notna()]\n",
    "\n",
    "#Mostramos la cantidad de registros después de la limpieza\n",
    "print(\"Cantidad de registros después de la limpieza:\", luminalDf.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbaaf73f",
   "metadata": {},
   "source": [
    "Al menos 15 registros estaban duplicados o nulos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253e8e4",
   "metadata": {},
   "source": [
    "---\n",
    "##### Analizamos los tipos de datos de las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2ccefa1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipos de datos de cada columna:\n",
      "Id                             object\n",
      "Fecha_De_Registro              object\n",
      "Fecha_De_Nacimiento            object\n",
      "Fecha_De_Dx_Biopsia            object\n",
      "Edad_Al_Dx_(Años)               int64\n",
      "Fecha_1°_Consulta_Om_Cecan     object\n",
      "Peso_Al_Dx                      int64\n",
      "Talla_Al_Dx                   float64\n",
      "Er_%                           object\n",
      "Pr_%                           object\n",
      "Her2_/_Neu                     object\n",
      "Her2_Ihq_+++                   object\n",
      "Fish/Sish                      object\n",
      "Ki67_%                         object\n",
      "Grado                          object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "print(\"Tipos de datos de cada columna:\")\n",
    "print(luminalDf.dtypes)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121b5823",
   "metadata": {},
   "source": [
    "##### Podemos identificar varios tipos de datos que no son correctos\n",
    "\n",
    "- Podemos convertir las fechas a datetime.\n",
    "- Los valores de Er_% y Pr_% deben ser convertidos a enteros.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8e4a649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fecha_De_Registro             datetime64[ns]\n",
      "Fecha_De_Nacimiento           datetime64[ns]\n",
      "Fecha_De_Dx_Biopsia           datetime64[ns]\n",
      "Fecha_1°_Consulta_Om_Cecan    datetime64[ns]\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Cambiamos fechas a datetime\n",
    "for col in luminalDf.columns:\n",
    "    if 'Fecha' in col:\n",
    "        luminalDf[col] = pd.to_datetime(luminalDf[col], errors='coerce') \n",
    "\n",
    "columnasFechas = [col for col in luminalDf.columns if 'Fecha' in col]\n",
    "\n",
    "\n",
    "print(luminalDf[columnasFechas].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2bc51b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Er_%      Int64\n",
      "Pr_%      Int64\n",
      "Grado     Int64\n",
      "Ki67_%    Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "\n",
    "luminalDf = luminalDf.copy()  \n",
    "luminalDf['Er_%'] = pd.to_numeric(luminalDf['Er_%'], errors='coerce').astype('Int64')\n",
    "luminalDf['Pr_%'] = pd.to_numeric(luminalDf['Pr_%'], errors='coerce').astype('Int64')\n",
    "luminalDf['Grado'] = pd.to_numeric(luminalDf['Grado'], errors='coerce').astype('Int64')\n",
    "luminalDf['Ki67_%'] = pd.to_numeric(luminalDf['Ki67_%'], errors='coerce').astype('Int64')\n",
    "\n",
    "\n",
    "print(luminalDf[['Er_%', 'Pr_%', 'Grado', 'Ki67_%']].dtypes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5bffed",
   "metadata": {},
   "source": [
    "---\n",
    "Una vez que corregimos los tipos de datos, verificamos que si estén correctos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "647d3eaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                                    object\n",
      "Fecha_De_Registro             datetime64[ns]\n",
      "Fecha_De_Nacimiento           datetime64[ns]\n",
      "Fecha_De_Dx_Biopsia           datetime64[ns]\n",
      "Edad_Al_Dx_(Años)                      int64\n",
      "Fecha_1°_Consulta_Om_Cecan    datetime64[ns]\n",
      "Peso_Al_Dx                             int64\n",
      "Talla_Al_Dx                          float64\n",
      "Er_%                                   Int64\n",
      "Pr_%                                   Int64\n",
      "Her2_/_Neu                            object\n",
      "Her2_Ihq_+++                          object\n",
      "Fish/Sish                             object\n",
      "Ki67_%                                 Int64\n",
      "Grado                                  Int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(luminalDf.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd73524",
   "metadata": {},
   "source": [
    "##### Buscamos datos únicos para cada columna \n",
    "\n",
    "Identificamos datos únicos para observar irregularidades, duplicados, valores "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5cd249c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Er_%\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[  10, <NA>,    0,   80,  100,   15,   20,   90,    2,   85,   70,   12,   98,\n",
      "   60,    5,   95,   30,   50,    4,   65,   40,    7,    1,   55,    8,    6,\n",
      "   75,    3,   91,   25,   96,   35,   99,    9,   16]\n",
      "Length: 35, dtype: Int64\n",
      "\n",
      "Columna: Pr_%\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[ 100,    5, <NA>,   60,   90,    0,   95,   40,   80,    2,   20,   70,   10,\n",
      "    3,   50,   25,   30,    8,    7,   35,   65,   75,   15,    1,   18,   22,\n",
      "   12,    4,   85,   99,   98,    6,   88,   92,   68,    9]\n",
      "Length: 36, dtype: Int64\n",
      "\n",
      "Columna: Her2_/_Neu\n",
      "Valores únicos:\n",
      "['Negativo ' 'Negativo' 'No aplica' 'Positivo' 'Desconocido']\n",
      "\n",
      "Columna: Her2_Ihq_+++\n",
      "Valores únicos:\n",
      "['1+' 'No aplica' '0+' '2+' '3+' 'Desconocido']\n",
      "\n",
      "Columna: Fish/Sish\n",
      "Valores únicos:\n",
      "['No aplica' 'Negativo' 'Positivo' 'Desconocido']\n",
      "\n",
      "Columna: Ki67_%\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[   5, <NA>,   20,    0,   90,   10,   50,   40,   60,    8,   65,   80,   95,\n",
      "   25,   30,   70,   15,   45,    3,   12,   47,   14,    7,   35,    2,    1,\n",
      "   75,   87,   18,  100,   24,   55,    4,   22,   67,   72,   11,   85,    9,\n",
      "   27,   89]\n",
      "Length: 41, dtype: Int64\n",
      "\n",
      "Columna: Grado\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[2, 3, <NA>, 1]\n",
      "Length: 4, dtype: Int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Obtenemos datos únicos para cada columna para estas columnas 'Er_%', 'Pr_%', 'Her2_/_Neu', que añada cada columna a un csv independiente\n",
    "\n",
    "try:\n",
    "    for col in ['Er_%', 'Pr_%', 'Her2_/_Neu', 'Her2_Ihq_+++','Fish/Sish', 'Ki67_%', 'Grado']:\n",
    "        if col in luminalDf.columns:\n",
    "            print(f'Columna: {col}\\nValores únicos:\\n{luminalDf[col].unique()}\\n')\n",
    "        else:\n",
    "            print(f'Columna {col} no encontrada en luminalDf\\n')\n",
    "            \n",
    "except Exception as e:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7aa7ed",
   "metadata": {},
   "source": [
    "---\n",
    "##### Hacemos la limpieza de los datos, esto incluyo:\n",
    "\n",
    "- Reemplazar las filas numéricas con valores de \"No Aplica\" y \"Desconocido\" por NaN, con la justificación\n",
    "  de que no cuentan con valores para catalogar en Luminal A y Luminal B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3386a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna: Er_%\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[  10, <NA>,    0,   80,  100,   15,   20,   90,    2,   85,   70,   12,   98,\n",
      "   60,    5,   95,   30,   50,    4,   65,   40,    7,    1,   55,    8,    6,\n",
      "   75,    3,   91,   25,   96,   35,   99,    9,   16]\n",
      "Length: 35, dtype: Int64\n",
      "\n",
      "Columna: Pr_%\n",
      "Valores únicos:\n",
      "<IntegerArray>\n",
      "[ 100,    5, <NA>,   60,   90,    0,   95,   40,   80,    2,   20,   70,   10,\n",
      "    3,   50,   25,   30,    8,    7,   35,   65,   75,   15,    1,   18,   22,\n",
      "   12,    4,   85,   99,   98,    6,   88,   92,   68,    9]\n",
      "Length: 36, dtype: Int64\n",
      "\n",
      "Columna: Her2_/_Neu\n",
      "Valores únicos:\n",
      "['Negativo' nan 'Positivo']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Borrar todas las filas que tengan en sus celdas de las columnas categóricas los valores 'No Aplica' o 'Desconocido'\n",
    "\n",
    "import numpy as np\n",
    "categorical_cols = ['Her2_/_Neu', 'Her2_Ihq_+++', 'Fish/Sish', 'Grado']  \n",
    "# Reemplazar 'No Aplica' y 'Desconocido' por np.nan en las columnas categóricas\n",
    "\n",
    "#Eliminar datos duplicados en las columnas categóricas, usar strip para verificar duplicidad\n",
    "\n",
    "luminalDf['Her2_/_Neu'] = luminalDf['Her2_/_Neu'].str.strip()\n",
    "luminalDf['Her2_Ihq_+++'] = luminalDf['Her2_Ihq_+++'].str.strip()\n",
    "luminalDf['Fish/Sish'] = luminalDf['Fish/Sish'].str.strip()\n",
    "\n",
    "\n",
    "\n",
    "for col in categorical_cols:\n",
    "    luminalDf[col] = luminalDf[col].replace(['No Aplica', 'No aplica', 'Desconocido', 'desconocido'], np.nan)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "try:\n",
    "    for col in ['Er_%', 'Pr_%', 'Her2_/_Neu', 'Her2_Ihq_+++','Fish/Sish', 'Ki67_%', 'Grado']:\n",
    "        if col in luminalDf.columns:\n",
    "            print(f'Columna: {col}\\nValores únicos:\\n{luminalDf[col].unique()}\\n')\n",
    "            luminalDf[col].to_csv(f'./resources/valores_unicos_{col}.csv', index=False)\n",
    "\n",
    "        else:\n",
    "            print(f'Columna {col} no encontrada en luminalDf\\n')\n",
    "            \n",
    "except Exception as e:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "36aef628",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Fecha_De_Registro</th>\n",
       "      <th>Fecha_De_Nacimiento</th>\n",
       "      <th>Fecha_De_Dx_Biopsia</th>\n",
       "      <th>Edad_Al_Dx_(Años)</th>\n",
       "      <th>Fecha_1°_Consulta_Om_Cecan</th>\n",
       "      <th>Peso_Al_Dx</th>\n",
       "      <th>Talla_Al_Dx</th>\n",
       "      <th>Er_%</th>\n",
       "      <th>Pr_%</th>\n",
       "      <th>Her2_/_Neu</th>\n",
       "      <th>Her2_Ihq_+++</th>\n",
       "      <th>Fish/Sish</th>\n",
       "      <th>Ki67_%</th>\n",
       "      <th>Grado</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>5448-17</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>1966-12-22</td>\n",
       "      <td>2017-11-14</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>81</td>\n",
       "      <td>1.68</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1352</th>\n",
       "      <td>5477-17</td>\n",
       "      <td>2017-11-27</td>\n",
       "      <td>1957-08-10</td>\n",
       "      <td>2017-11-22</td>\n",
       "      <td>60</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>75</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1353</th>\n",
       "      <td>5479-17</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>1964-05-19</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>53</td>\n",
       "      <td>2017-12-06</td>\n",
       "      <td>74</td>\n",
       "      <td>1.62</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>5482-17</td>\n",
       "      <td>2017-09-19</td>\n",
       "      <td>1973-02-26</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>44</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>73</td>\n",
       "      <td>1.66</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>3+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1355</th>\n",
       "      <td>5485-17</td>\n",
       "      <td>2017-06-27</td>\n",
       "      <td>1966-12-17</td>\n",
       "      <td>2017-07-19</td>\n",
       "      <td>50</td>\n",
       "      <td>2017-12-27</td>\n",
       "      <td>67</td>\n",
       "      <td>1.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>3+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1356</th>\n",
       "      <td>5486-17</td>\n",
       "      <td>2017-11-29</td>\n",
       "      <td>1976-02-03</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>41</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>55</td>\n",
       "      <td>1.47</td>\n",
       "      <td>95</td>\n",
       "      <td>90</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>2+</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1357</th>\n",
       "      <td>5487-17</td>\n",
       "      <td>2017-07-26</td>\n",
       "      <td>1964-01-06</td>\n",
       "      <td>2018-02-09</td>\n",
       "      <td>54</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>66</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1358</th>\n",
       "      <td>5497-17</td>\n",
       "      <td>2016-08-16</td>\n",
       "      <td>1955-11-20</td>\n",
       "      <td>2018-02-12</td>\n",
       "      <td>62</td>\n",
       "      <td>2017-12-20</td>\n",
       "      <td>76</td>\n",
       "      <td>1.60</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>5512-17</td>\n",
       "      <td>2017-03-11</td>\n",
       "      <td>1959-08-05</td>\n",
       "      <td>2017-11-23</td>\n",
       "      <td>58</td>\n",
       "      <td>2017-12-12</td>\n",
       "      <td>63</td>\n",
       "      <td>1.60</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>3+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>5561-17</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>1960-05-01</td>\n",
       "      <td>2018-05-05</td>\n",
       "      <td>58</td>\n",
       "      <td>2018-02-19</td>\n",
       "      <td>60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1361</th>\n",
       "      <td>5572-17</td>\n",
       "      <td>2017-11-07</td>\n",
       "      <td>1945-10-25</td>\n",
       "      <td>2018-12-15</td>\n",
       "      <td>73</td>\n",
       "      <td>2018-01-09</td>\n",
       "      <td>92</td>\n",
       "      <td>1.58</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1362</th>\n",
       "      <td>5575-17</td>\n",
       "      <td>2017-12-18</td>\n",
       "      <td>1957-05-15</td>\n",
       "      <td>2017-10-15</td>\n",
       "      <td>60</td>\n",
       "      <td>2018-01-11</td>\n",
       "      <td>61</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>3+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1363</th>\n",
       "      <td>5580-17</td>\n",
       "      <td>2016-04-05</td>\n",
       "      <td>1963-04-18</td>\n",
       "      <td>2017-12-16</td>\n",
       "      <td>54</td>\n",
       "      <td>2018-01-12</td>\n",
       "      <td>95</td>\n",
       "      <td>1.60</td>\n",
       "      <td>75</td>\n",
       "      <td>60</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>5592-17</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>1971-12-28</td>\n",
       "      <td>2017-12-29</td>\n",
       "      <td>46</td>\n",
       "      <td>2018-01-16</td>\n",
       "      <td>81</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positivo</td>\n",
       "      <td>3+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1365</th>\n",
       "      <td>5597-17</td>\n",
       "      <td>2017-01-31</td>\n",
       "      <td>1961-04-06</td>\n",
       "      <td>2015-07-09</td>\n",
       "      <td>54</td>\n",
       "      <td>2018-01-08</td>\n",
       "      <td>45</td>\n",
       "      <td>1.45</td>\n",
       "      <td>100</td>\n",
       "      <td>60</td>\n",
       "      <td>Negativo</td>\n",
       "      <td>0+</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id Fecha_De_Registro Fecha_De_Nacimiento Fecha_De_Dx_Biopsia  \\\n",
       "1351   5448-17        2017-11-22          1966-12-22          2017-11-14   \n",
       "1352   5477-17        2017-11-27          1957-08-10          2017-11-22   \n",
       "1353  5479-17         2017-05-24          1964-05-19          2017-11-29   \n",
       "1354   5482-17        2017-09-19          1973-02-26          2017-10-01   \n",
       "1355   5485-17        2017-06-27          1966-12-17          2017-07-19   \n",
       "1356   5486-17        2017-11-29          1976-02-03          2018-01-16   \n",
       "1357   5487-17        2017-07-26          1964-01-06          2018-02-09   \n",
       "1358   5497-17        2016-08-16          1955-11-20          2018-02-12   \n",
       "1359   5512-17        2017-03-11          1959-08-05          2017-11-23   \n",
       "1360   5561-17        2017-07-01          1960-05-01          2018-05-05   \n",
       "1361   5572-17        2017-11-07          1945-10-25          2018-12-15   \n",
       "1362   5575-17        2017-12-18          1957-05-15          2017-10-15   \n",
       "1363   5580-17        2016-04-05          1963-04-18          2017-12-16   \n",
       "1364   5592-17        2017-06-21          1971-12-28          2017-12-29   \n",
       "1365   5597-17        2017-01-31          1961-04-06          2015-07-09   \n",
       "\n",
       "      Edad_Al_Dx_(Años) Fecha_1°_Consulta_Om_Cecan  Peso_Al_Dx  Talla_Al_Dx  \\\n",
       "1351                 50                 2017-11-22          81         1.68   \n",
       "1352                 60                 2017-12-06          75         1.60   \n",
       "1353                 53                 2017-12-06          74         1.62   \n",
       "1354                 44                 2017-11-29          73         1.66   \n",
       "1355                 50                 2017-12-27          67         1.56   \n",
       "1356                 41                 2018-01-08          55         1.47   \n",
       "1357                 54                 2018-01-09          66         1.58   \n",
       "1358                 62                 2017-12-20          76         1.60   \n",
       "1359                 58                 2017-12-12          63         1.60   \n",
       "1360                 58                 2018-02-19          60         1.60   \n",
       "1361                 73                 2018-01-09          92         1.58   \n",
       "1362                 60                 2018-01-11          61         1.57   \n",
       "1363                 54                 2018-01-12          95         1.60   \n",
       "1364                 46                 2018-01-16          81         1.60   \n",
       "1365                 54                 2018-01-08          45         1.45   \n",
       "\n",
       "      Er_%  Pr_% Her2_/_Neu Her2_Ihq_+++ Fish/Sish  Ki67_%  Grado  \n",
       "1351   100     3   Negativo           0+       NaN      60      3  \n",
       "1352     0     0   Negativo           0+       NaN      80      2  \n",
       "1353   100    10   Negativo           0+       NaN      35      3  \n",
       "1354    80     0   Positivo           3+       NaN      20      3  \n",
       "1355     0     0   Positivo           3+       NaN    <NA>      2  \n",
       "1356    95    90   Negativo           2+  Negativo    <NA>      1  \n",
       "1357     0     0   Negativo           0+       NaN    <NA>      3  \n",
       "1358   100   100   Negativo           0+       NaN       5      2  \n",
       "1359   100     0   Positivo           3+       NaN      30      2  \n",
       "1360     0     0   Negativo           0+       NaN      30      3  \n",
       "1361   100   100   Negativo           0+       NaN       3      2  \n",
       "1362     0     0   Positivo           3+       NaN    <NA>      3  \n",
       "1363    75    60   Negativo           0+       NaN    <NA>      2  \n",
       "1364     0     0   Positivo           3+       NaN      30      3  \n",
       "1365   100    60   Negativo           0+       NaN    <NA>      3  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luminalDf.tail(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1c309a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id                               0\n",
      "Fecha_De_Registro                0\n",
      "Fecha_De_Nacimiento              1\n",
      "Fecha_De_Dx_Biopsia              1\n",
      "Edad_Al_Dx_(Años)                0\n",
      "Fecha_1°_Consulta_Om_Cecan       3\n",
      "Peso_Al_Dx                       0\n",
      "Talla_Al_Dx                      0\n",
      "Er_%                            30\n",
      "Pr_%                            31\n",
      "Her2_/_Neu                      31\n",
      "Her2_Ihq_+++                    29\n",
      "Fish/Sish                     1253\n",
      "Ki67_%                         501\n",
      "Grado                           15\n",
      "dtype: int64\n",
      "1    818\n",
      "2    435\n",
      "0     61\n",
      "7     13\n",
      "6     11\n",
      "3      5\n",
      "4      5\n",
      "5      3\n",
      "Name: count, dtype: int64\n",
      "Cantidad de registros: 1351\n"
     ]
    }
   ],
   "source": [
    "print(luminalDf.isna().sum())  # Nulos por columna\n",
    "print(luminalDf.isna().sum(axis=1).value_counts()) \n",
    "\n",
    "\n",
    "print(\"Cantidad de registros:\", luminalDf.shape[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
